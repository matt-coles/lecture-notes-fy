# Parallel

It is claimed that UPC, is simple to code than MPI and has lower overhead than
MPI. On the other hand MPI recognises that large infrequent transfer are more
efficient, less relative overhead, than small frequent transfers. It could be
argued that making MPI harder to use means you spend more time thinking about
these essential issues. UPC might tend to encourage less thought as you can't
explicitly see the cost. UPC is currently being pushed as alternative to MPI: we
have yet to see if it will be successful. The GNU project supports GNU UPC as a
modification of GCC. There is talk of having direct UPC support in later GCCs,
which will massively increase it's availability.

The next major architecture to consider is SIMD. Each processor is controlled by
a single control unit so are all executing the same instruction. Each processor
has its own chunk of private memory and shared chunk of global memory.
Processors can be strung linearly in a vector, or in a square as a mesh. Of
course you can use an array as a vector or a vector as an array with a modest
loss of efficiency. Vector processors appeared quite early on in architectures
(1960s) and were a mainstay in 1980s supercomputers (Crays), as they are a
relatively simple extension of the uniprocessor. Array processors have come into
fashion and gone away again several times. Similarly SWAR instructions owe
something to vector design. With SIMD we can parallelise loops that perform the
same operation on arrays. The important points being, all elements in the arrays
are being treated identically and there is no interference between any of the
operations. The second point meaning that there are no races, meaning no
serialisation is required.
