### Parallel Computing

-- Introductory BS --

There is no singular model for parallel computing, akin to von Neumann model for
sequential programming, programs must be targeted to specific machines. See
slide 36 for books. Parallel computing is not completely about making things go
faster, it is much better at making things larger, i.e. creating more output in
the same amount of time rather than the same amount of output in less time.

Process parallelism or task parallelism is about making tasks go faster whereas
data parallelism is about making the output larger. The reason that process
parallelism does not scale as easily as data parallelism because there is
overhead in the division of work and coordination - sometimes they are so large
that they are larger than the original problem, thus making small problems often
slower than just doing it sequentially.

Programming sequential machines is hard enough as it is, in that it is not a
solved problem and people do not know the best way of writing correct programs.
The same is true for parallel programming, but there are also additional
problems. 

The terms parallel and concurrent are often used interchangeably. Concurrent
means that your computation is in separately executable parts, they are
independent of each other and there is no requirement for the code to run at the
same time. Parallel means that the code ___is___ running at the same time.
Concurrency is much more about structure of a program whereas parallelism is
about the actual runtime.
