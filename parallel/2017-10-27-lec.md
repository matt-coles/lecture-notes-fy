# Parallel Computing

### Concurrency Primitives

Some machine architectures support more sophisticated mechanisms. For example
Intel, have Transactional Synchronisation eXtensions (TSX) in their latest
chips. This allows multiple threads to work on shared data with potentially less
lock contention. This is somewhat like the way databases deal with parallel
updates in such a way the common case of non-conflicting updates is dealt with
efficiently while conflicting updates are a bit more expensive (using
rollbacks). This is done in hardware with special machine instructions.
Similarly ARM has Reservation that watch out for simultaneous updates to memory
locations. MIPS has an ITU and LL/SC instructions.

Locks are definitely needed when we update (read then modify) the value of a
variable. The question arises regarding whether we need a lock around a simple
read of a (multi byte) value. It is easy to believe some bytes of a value might
be written while half way through being read, resulting in a mix of the bits of
the old and new values. However for most machines these days it will be safe to
read simple values like integers and doubles that will fit in a register: the
hardware read will be atomic.

Locks should always be per-resource, unless there are severe memory limitations
but doing shared locks sequentialises the program a lot.

Some people say that locks are too low level which makes them too easy to use
incorrectly and cause deadlocks.

A lock can implemented as a 'flag' - for example an integer. Test the flag, if
it is already 1, wait; else we can grab it by setting the flag to 1. However,
there will be a race condition if this test and set is not *atomic*.

There is a hardware solution such that there will be a special machine
instruction for doing such things. (MIPS has sltiu, Intel has cmpxchgb, "compare
and exchange byte"). There are software solutions, such as Dekker, Dijkstra and
Lamport. These are very subtle as they must construct an atomic effect from
non-atomic code.
