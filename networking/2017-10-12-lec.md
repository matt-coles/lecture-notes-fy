### Networking

A typical email application will need to apply a presentation encapsulation and add application layer headers, To/From etc. There is a standard out there, the Multipurpose Internet Mail Extensions (MIME) for encoding data in a safe way. MIME was originally developed for email, but it is useful in many other contexts, such as Web page delivery.

This is similarly true for the session layer. If a persistent session is required, the application must provide the code to do this. Many applications like FTP do not. If TCP/IP had session management, applications would get this 'for free'. The counter-argument is that many applications do not want session management and should not have to pay the overhead. In the real world, there is no session management in TCP so you need to reimplement this, or rather find a library to do this and write the code to incorporate this. i.e Taco Bell programming.

An example of layer of how an email might be transmitted over an Ethernet.

  - We start with the text of the email
  - The application transforms the text using a MIME encoding (presentation layer)
  - Application adds an envelope header (From, To etc) (application layer)
  - TCP adds it's headers for reliability (transport layer)
  - IP adds it's headers for routing (network layer)
  - Ethernet adds a header (local routing) and a trailer (checksum) (datalink layer)
  - The bits are transformed using a 4B/5B encoding to smooth the bit patterns and are sent using a 3-level electrical coding MLT-3 (physical layer)

There are two layering models, which are two approaches to designing a standard, so which is better? 

  - OSI model was developed before an implementation; the Internet model was created after TCP/IP to match.
  - OSI makes a clear distinction between model and implementation; Internet model is much more fuzzy
  - OSI is general and can be applied to many systems however the Internet model only really applies to TCP/IP
  - Implementations following the OSI model were awful and TCP/IP is wildly successful

There are problems with the Internet Model (*not* TCP/IP), these include it only being good for describing TCP/IP, the physical and datalink layer are merged - upsets EE people. Non-problems include, OSI is slower because it goes through more layers - this is false in so many ways. There are good CS reasons why we should do this separation but practically we have to make tradeoffs. Another myth is that OSI has larger encapsulation overhead as data has to go through more layers. The model does not say you must have encapsulation at each layer, it depends on what the standard you are implementing requires. One final myth is that there are no decent implementations of OSI, again this confuses a model with a standard it is possible to map TCP/IP to fit the OSI model anyway.

The main reason that TCP/IP is so successful is partly because the standards (RFCs) are open and freely available, anyone can join in. Networks before the Internet tended to be closed and proprietary where you had to pay to get in. All of the proprietary networks failed to reach critical mass and had to give up on and join the Internet using TCP/IP. Other layering models do exist e.g. Tanenbaums Five Layer Model (Physical, Data Link, Network, Transport and Application). This is still missing the presentation layer but is more useful in a world where the physical layer is often changed. 

Despite initially being developed by the Military, the Internet was mostly designed and developed in academia. This has had a great effect on the *security* of the Internet. The Internet was developed in a safe academic environment where little regard was given to issues of privacy or authentication. And the models are alo weaker on security than they ought to be. OSI does say that security should be involved at all layers which is not hugely helpful.

By default data is readable as it is passed through the various machines on the path to the destination. Many protocols are not resistant to malicious inteference. Authentication mechanisms are weak to non-existent i.e. that you are talking to the person you think you are, or are authorised to perform an action. Many of these issues have since been tackled, particularly once commerce got involved and people could lose money. There is still much room for improvement. New protocols and secure extensions to existing protocols are now available: e.g. HTTPS for the Web and SMTPS for email. Management and use of cryptography has overhead, this is an extra workload on servers, which some people are not willing to pay.

## Hardware

# Ethernet

There are several popular hardware implementations, for example Ethernet (wired) and WiFi (wireless).

Ethernet arose in 1982 from DEC, Intel and Xerox, based on the earlier Aloha protocol. The original Ethernet supported up to 10Mb/s. It used carrier senese, multiple access with collision detection (CSMA/CD). Current high end Ethernet runs at 100Gb/s with 400Gb/s coming soon and there are plans for 1Tb/s. More precisely the original Ethernet had a 10Mb/s signalling rate. The signalling rate is the rate of delivery of bits across the physical network. Due to layering encapsulation and other overheads this is not the rate of delivery of bits to the application you are running. However this is the number that marketers like to use. The rate actually realised can be much lower e.g. a 54Mb/s WiFi network might only deliver half that figure to an application. The Ethernet standard covers both the PHY and the MAC layers, so we shall look at them together. And we begin with the frame format.

An Ethernet frame consists of

```
+--------------------------+---------------------+-----------+-----------------+----------+
| Destination Address (6b) | Source Address (6b) | Type (2b) | Data (46-1500b) | CRC (4b) |
+--------------------------+---------------------+-----------+-----------------+----------+
```

The 2 byte type, indicates what kind of data follows e.g 0x0800 for an IP packet. The data is a maximum of 1500 bytes. The data size is an important choice as too small and it requires too many packets, and too large and corruption causes a big loss. The minimum size is 46 bytes, the data must be padded if fewer than 46 are sent. A higher layer should detect and remove this padding when necessary. The final section is a 4 byte checksum, called a cyclic redundancy check. Ethernet is shared so every host sees every frame on the local network. However every Ethernet card has a unique address built into it. So the destination address allows an Ethernet card in a host to recognise that a frame is for itself and can read and process it. There is a security issue here. The source address allows a host to determine who sent the frame and so it can reply if needed. The source address allows a host to determine who sent the frame and so it can reply if needed. For convenience this is usually written as 6 hexadecimal bytes. This is fine when the destination is on the local Ethernet network, we have to work harder if the destination is non-local but that is the job of the next layer, IP. Ethernet is a multiple access medium meaning that several hosts use the same piece of wire to send data to one another, this means there must be collision detection. If a host is already sending data, the whole network is occupied and others hosts must wait. If two hosts try to send simulatenously there will be a collision. To get around this, an Ethernet host first listens to see if anyone else is using the network - this is called *carrier sense*. If not, it sends the data otherwise it waits. This still isn't quite enough, because it is possible for two hosts to send at exactly the same time causing a collision. Each host continues to listen while transmitting to make sure there are no collisions - this is called *collision detection*. If a collision is detected the host will stop and wait for a small random period of time and then try again with carrier sense. Collision detection is the reason that there has to be a minimum data size. The frames must be on the wire long enough for the hardware to detect the collision, this is to do with the speed of the signal in the wire. There have been many Ethernet physical layers, with varying thicknesses and maximum lengths etc.

There are many categories of Ethernet cables too, these largely provide a frequency rating. People are trying hard to make new Ethernet standards that don't require ripping out the old cabling and installing a new set.

Previously you could connect everything to a network, but now it requires a *hub* or *switch*. Hubs were simple repeaters that sent incoming signals on all outputs. There was a single collision domain as all hosts see all signals. The available bandwidth is shared amongst all the hosts. A switch understands the link layer and it only sends the signal out on the single wire that has the destination host. They therefore read the MAC addresses in the frams and to track which socket each host is plugged into. This is extra complexity in the switch hardware but reduces the number of possible collisions increasing the throughput. Each output cable is now a separate collision domain. The full bandwidth is available on each output simulatenously. If the output is busy, rather than having a collision a switch can choose to buffer a packet and send them when the output is free. This doesn't eliminate the need for CSMA/CD because buffers can fill up, the switch can send a jamming signal to get it to back off. Additionally some switches can *cut through*, sending through the start of the packet before the tail has arrived - this just simply increases throughput and reduces latency however could potentially forward corrupted packets and cause collisions. Switches can run in *full duplex* mode with independent inward and outward traffic to each host, which technically gives twice the toal bandwidth. No collisions are possible between opposing traffic below 1gb.
