### Networking

A typical email application will need to apply a presentation encapsulation and add application layer headers, To/From etc. There is a standard out there, the Multipurpose Internet Mail Extensions (MIME) for encoding data in a safe way. MIME was originally developed for email, but it is useful in many other contexts, such as Web page delivery.

This is similarly true for the session layer. If a persistent session is required, the application must provide the code to do this. Many applications like FTP do not. If TCP/IP had session management, applications would get this 'for free'. The counter-argument is that many applications do not want session management and should not have to pay the overhead. In the real world, there is no session management in TCP so you need to reimplement this, or rather find a library to do this and write the code to incorporate this. i.e Taco Bell programming.

An example of layer of how an email might be transmitted over an Ethernet.

  - We start with the text of the email
  - The application transforms the text using a MIME encoding (presentation layer)
  - Application adds an envelope header (From, To etc) (application layer)
  - TCP adds it's headers for reliability (transport layer)
  - IP adds it's headers for routing (network layer)
  - Ethernet adds a header (local routing) and a trailer (checksum) (datalink layer)
  - The bits are transformed using a 4B/5B encoding to smooth the bit patterns and are sent using a 3-level electrical coding MLT-3 (physical layer)

There are two layering models, which are two approaches to designing a standard, so which is better? 

  - OSI model was developed before an implementation; the Internet model was created after TCP/IP to match.
  - OSI makes a clear distinction between model and implementation; Internet model is much more fuzzy
  - OSI is general and can be applied to many systems however the Internet model only really applies to TCP/IP
  - Implementations following the OSI model were awful and TCP/IP is wildly successful

There are problems with the Internet Model (*not* TCP/IP), these include it only being good for describing TCP/IP, the physical and datalink layer are merged - upsets EE people. Non-problems include, OSI is slower because it goes through more layers - this is false in so many ways. There are good CS reasons why we should do this separation but practically we have to make tradeoffs. Another myth is that OSI has larger encapsulation overhead as data has to go through more layers. The model does not say you must have encapsulation at each layer, it depends on what the standard you are implementing requires. One final myth is that there are no decent implementations of OSI, again this confuses a model with a standard it is possible to map TCP/IP to fit the OSI model anyway.

The main reason that TCP/IP is so successful is partly because the standards (RFCs) are open and freely available, anyone can join in. Networks before the Internet tended to be closed and proprietary where you had to pay to get in. All of the proprietary networks failed to reach critical mass and had to give up on and join the Internet using TCP/IP. Other layering models do exist e.g. Tanenbaums Five Layer Model (Physical, Data Link, Network, Transport and Application). This is still missing the presentation layer but is more useful in a world where the physical layer is often changed. 

Despite initially being developed by the Military, the Internet was mostly designed and developed in academia. This has had a great effect on the *security* of the Internet. The Internet was developed in a safe academic environment where little regard was given to issues of privacy or authentication. And the models are alo weaker on security than they ought to be. OSI does say that security should be involved at all layers which is not hugely helpful.

By default data is readable as it is passed through the various machines on the path to the destination. Many protocols are not resistant to malicious inteference. Authentication mechanisms are weak to non-existent i.e. that you are talking to the person you think you are, or are authorised to perform an action. Many of these issues have since been tackled, particularly once commerce got involved and people could lose money. There is still much room for improvement. New protocols and secure extensions to existing protocols are now available: e.g. HTTPS for the Web and SMTPS for email. Management and use of cryptography has overhead, this is an extra workload on servers, which some people are not willing to pay.

# Hardware

There are several popular hardware implementations, for example Ethernet (wired) and WiFi (wireless).

Ethernet arose in 1982 from DEC, Intel and Xerox, based on the earlier Aloha protocol. The original Ethernet supported up to 10Mb/s. It used carrier senese, multiple access with collision detection (CSMA/CD). Current high end Ethernet runs at 100Gb/s with 400Gb/s coming soon and there are plans for 1Tb/s. More precisely the original Ethernet had a 10Mb/s signalling rate. The signalling rate is the rate of delivery of bits across the physical network. Due to layering encapsulation and other overheads this is not the rate of delivery of bits to the application you are running. However this is the number that marketers like to use. The rate actually realised can be much lower e.g. a 54Mb/s WiFi network might only deliver half that figure to an application. The Ethernet standard covers both the PHY and the MAC layers, so we shall look at them together. And we begin with the frame format.

An Ethernet frame consists of

```
| Destination Address (6) | Source Address (6) | Type (2) | Data (46-1500) | CRC (4) |
```

The 2 byte type, indicates what kind of data follows e.g 0x0800 for an IP packet. The data is a maximum of 1500 bytes.
