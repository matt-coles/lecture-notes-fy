# Networking

The next strategy is aimed at getting the largest segment size a connection can
handle. But not too large. IP layer fragmentation is expensive so we employ path
MTU discovery. We can send segments of decreasing size, starting with the
minimum of the MSS of the sending interface and the MSS announced by the other
end (in the TCP setup handshake), or 526 if the other end did not give an MSS.
And with the IP flag DF set. There is some cross-layer activity here which in
theory should not happen but is important. IF an ICMP error "fragmentation
needed but DF set" happens during a connection, the congestion window should
remain unchanged, but a slow start should begin. This is to reflect the fact
that it's not congestion at fault here, but we do need to back off a bit to
allow ACKs to start coming through again. It is recommended you try a larger ITU
once in a while e.g. every 10 minutes as routes can vary dynamically. 

TCP has several timers. Two mentioned already are 2MSL and the delayed ACK
timer. There is also a timer that determines when to resend in the absence of an
ACK: a retransmission time-out (RTO). If one is to wait too short of a time, it
will resend extraneously on a network that is slow but otherwise reliable. If
you wait too long, it is poor for the data rate if the data is not getting
through. We also want dynamic behaviour that adapts to changing conditions
rather than a simple fixed time-out. If the network slows down, the timeout
should increase. IF the network speeds up the timeout should decrease. Jacobson
gave an easy algorithm: keep a variable, the round trip time (RTT) for each
connection. RTT is the best current estimate for the time of a segment going out
and the ACK returning. If we haven't received an ACK in approximately this time,
deem it lost. When a segment is sent, you start a timer. If the ACK returns
before the timeout, TCP looks at the actual round trip time M and updates RTT
using.

`
RTT = aRTT + (1-a)M
`

a is a smoothing factor, usually 7/8 for easy arithmetic. Thus RTT increases or
decreases smoothly as conditions change and doesn't get too upset by the
occasional straggler that is unusually late or early. Next, we need to determine
a timeout interval given RTT. This should take the standard deviation of RTT
into account: if the measured RTTs have a large deviation it makes sense to have
a larger timeout. True standard deviations are tricky to compute quickly (square
roots), so Jacobson suggested using the mean deviation. The mean deviation is:

`
D = BD + (1 - B)|RTT-M|
`

D is close to the standard deviation and is much easier to calculate quickly. A
typical value for B is 3/4. The timeout value is then set to:

`
T = RTT + 4D
`

The "magic" numbers were found to be good in practice. When sending a segment,
set the timer to expire after time T. If the timer expires before the ACK is
received, we resend the segment of course. We also need to update RTT somehow.
We can't use the RTT of the resent segment as we might get the somewhat delayed
ACK of the original segment. This is called the retransmission ambiguity
problem. The measured RTT would be much too small. Karn's algorithm is to double
the timeout T on each failure, but do not adjust RTT. When segments start
getting through normal RTT updates continue and RTT will adjust to whatever it
needs to be. This doubling is called exponential backoff. Alternatively, as is
common these days, we have the optional header and this solves the
retransmission ambiguity directly. A TCP option timestamp is a 32 bit unsigned
integer with no particular precision specified: just something that matches the
precision of the retransmit timer. Something in the range 1ms-1s precision is
suggestion.

The next timer in TCP is the persist/persistence timer. Its role is to prevent
deadlock through the loss of window update segments. The persistence timeout is
a timer set when an ACK with a window size of zero is received. If the host does
not receive a duplicate ACK with a new window size before this timer runs out,
then the host must send a new window probe to check the available window size
from the destination. If the window is still 0 then the host can reset the timer
and wait again. The persist timer starts with something like 1.5 second doubling
with each probe and is rounded up or down to lie within 5 to 60 seconds. The
persist mechanism never gives up, sending window probes until either the window
opens, or the connection closes. The persist timer is unset when a non-zero
window is received.

A further timer in TCP is the keepalive. This is an optional part of the TCP/IP
standard, and some implementations do not have it as it is occasionally regarded
as controversial. When a TCP connection is idle, no data flows between source
and destination. So part of the path could break and be restored and the
connection is none the wiser. This gives some level of resilience against flaky
networks. On the other hand, sometimes the server wants to know if the client is
still alive: each client TCP connection uses some resources in the server
(buffers etc.). IF the client has crashed these resources could better be used
elsewhere. To solves this the server sets a keepalive timer when the connection
goes idle. A typical value is 2 hours. When the timer expires the server can
send a keepalive probe, this is simply an empty segment (i.e. no data). If the
server gets an ACK, everything is OK and the client is still there. If not, the
server might conclude the client is no longer active. There are four cases:

- The client is up and running: the keepalive probe is ACKed and everybody is
    happy. The keepalive timer is reset to 2 hours.
- the client crashed or is otherwise not responding to TCP: the server gets no
    ACK and resends after 75 seconds. After 10 probes. 75 seconds apart, if
    there is no response the server terminates the connection with "connection
    timed out" sent to the server application.
- the client has crashed and rebooted. The client gets the probe and responds
    with a RST. The server gest the RST and terminates the connection with
    "connection reset by peer" sent to the application.
- The client is unreachable but otherwise up and running e.g. broken routing.
    This is indistinguishable from the second case so the same events ensue.

There are several reasons not to use keepalive:

- They can cause a generally good connection to be closed because of an
    intermittent failure of a router
- They use bandwidth
- Some network operators charge per packet.

The latter two are not particular good arguments, particular in this day and
age, as the cost is just a couple of packets every 2 hours. It is usually
possible to disable keepalive in the application: some people think that
keepalive should not be in the TCP layer, but should be handled by the
application layer (i.e. the non-existent session layer). 

Many other strategies have been proposed to improve throughput. Some have been
widely adopted. TCP is a huge success: from 1200 bits/sec telephone lines to
gigabit networks and beyond it has turned out to be massively flexible and
scalable.

### Presentation

We must have some way of deciding what the bytes in a TCP packet actually mean
to an application. Suppose I want to send the word "Plan" to you. What do I
send? If we both use ASCII to encode characters, I might send four bytes, 80,
108, 97, 110. To use EBCDIC, for example, it would be 215, 147, 129, 149. Some
other encoding might need more than four bytes. If we are using different
encodings, the machines need to have some way of communicating that information.
There are solutions but they will not be examined.

### Security

IP was originally developed in a "safe" academic environment. Little thought was
given to security or authentication. And early code had a lot of fragile
implementations, however this fast development led to IP's early acceptance and
success. And this also meant experimental and poorly debugged code was rapidly
incorporated into a large number of systems. There are generic bugs that appear
in many products as there are a lot of shared codebase's or similar assumptions.
Some are fairly benign such as TTL being used as a hop count rather than an
actual time. Others are less so and can be exploited to do things such as, crash
the machine, tie up the machine with so much bogus data that real traffic can't
get through (denial of service) or gain control over the machine which can then
be used to attack a more important target or send spam.

Today the Internet is not a safe place as people are trying to use it for
monetary, political or other gain, or to simply be a nuisance. There must be
tools to protect ourselves against these things. Technology plays a large part
in this, but psychology of the users is just as important. Why bother attacking
a machine when you can attack the human element? Such as phoning a support
engineer and pretending to be a user who has forgotten their password.
Additionally, you can send someone an email land getting them to click a link or
run some code. A network can be attacked in many ways, we shall look at a few
simple examples.

SYN floods. A denial of service attack. A TCP connection starts with a SYN. The
server then sends a SYN+ACK which the client ACKs. The server must save a chunk
of information about the initial SYN so it can recognise the client ACK as part
of the new connection' and the options like SACK or MSS. A SYN flood is where an
attacker sends very many active open SYN segments but never completes the
handshake. The SYN segments might come from a single source, but more likely
from very many hacked computers in a _distributed_ denial of service attack. The
hacked machines comprise a botnet, controlled by the hacker(s). The individual
hosts are sometimes called zombies. Each SYN received consumes resources on the
server that are not released until a suitable timeout period has passed. Thus
the server can run out of resources and not be able to respond to real
connections. The overload reduces the level of service for genuine users, often
down to zero. This has been used many times, particularly in extortion attacks
against commercial sites to get them to pay a ransom. These days also used to
exert political pressure against companies, people or governments. A DDOS attack
might be serveral GB/s of SYNs. Remedies include the server starting to drop
half-open connections when resources are low. Say oldest first, or at random.
Real connections might get dropped but the probabilities are that the attack
connections are dropped. Alternatively, use _syncookies_. Store no information
on the server but encode it in the server's initial sequence number (ISN) for
this connection. So the ISN is not random, but now encodes some information: it
is called a syncookie. When the client ACK gets back we can decode the returned
sequence number to retrieve the information. Now resources can safely be
allocated to this presumably valid connection. This is good as it consumes no
resources in the server, however it is difficult to encode all the information
in only 32 bits of the ISN, and it must be encrypted to prevent spoofing. It is
not big enough to include any negotiated options, such as "SACK available". So
syncookies are only used when the load gets very high.

Implementation attacks. These exploit bugs in IP implementations. Some hosts
were vulnerable to oversized ping packets: the "ping" of death. These were sent
as forged fragments that, when reassembled, were much larger than expected and
overflowed internal buffers. The result was a crash/denial of service. The
mitigation is just to ignore ICMP packets larger than the MTU: such packets are
never generated naturally, or fix the reassembly code.

A fragment bomb is like a SYN flood. Too many fragments for a packets that are
never completed and so can't be reassembled. This overflows fragment buffer space
and likely causes a denial of service or crash. Again, implementations need to
time-out and drop old fragments.

Recent botnets have used the Internet of Things which is connected devices like
security cameras, fridges, thermostats and so on, that are often poorly secured
are still using default passwords, or are running old vulnerable software. The
Mirai botnet has been implicated in a DDOS attack of over 1TB/s. This was a DNS
amplification attack: a small DNS lookup request is sent to a server with a
reply address forged to that of the target. A large amount of DNS reply is sent
to the target. The DNS servers are also tied up with bogus requests, further
restricting easy access to the target. Many other exploits of implementation
exists. Usually form the implementers making invalid assumptions about IP and
assuming that packets are all well-formed and correct.

- Jolt: fragment ICMP packets
- Land attack. The source addresses on TCP SYNs are the same as the destination
    and the server tried respond to itself.
- Teardrop. Overlapping fragments cause problems on reassembly.
- New tear-drop. Overlapping fragments on a UDP packet reassemble to form a
    packet with an invalid header
- Zero length fragments. In some implementations these were stored but never 
    used thus storage was exhausted.
- Amplification attacks. Where the source sends a packet to a third party with
    the reply address forged to that of the attacked host. The replies flood the
    attacked host.
- And so on.

Making a robust implementation is hard.

There are a pre-computer attack, formerly known as a confidence trick, nowadays
referred to as a social engineering attack. If the machine is too hard to
attack, attack the user instead. Often this is much easier than a machine
attack. It could be as simple as phoning up a systems administrator and
persuading them to give you a password to their machine.

- Pretend to be a supervisor and threaten to sack them if they do not comply
- Pretend to be a distraught user who has lost their password
- Anything else to unbalance them or get their sympathy.

This is much easier than trying to crack a password by brute force. Another
attack is phishing. This is a form of impersonation to try and convince the user
to hand over valuable information such as credit card numbers. A typical
phishing attack is:

- The victim receives an email purporting to be from there bank asking them to
    update their personal details. The email provides a convenient WWW link.
- The page looks like the bank's
- The victim enters their details and sends them off
- The email and Web page are fakes and send the information to the hackers.

Similar for many other attacks such as the 419 or Nigerian fraud named after the
South African police code used to identify this approach.
