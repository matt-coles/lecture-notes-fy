# Networking

There is another rule concerning delayed ACKs. If you get an out-of-order
segment, you _must_ not delay but send an ACK immediately. This may be a
duplicate ACK of one you sent earlier. This is to inform the sender as soon as
possible that something might have gone wrong - the other end will wait for
three duplicate ACKs. 

When sending keystrokes over a network there is a lot of wasted bandwidth. A
keystroke could in theory be 1 byte, this would be sent in a TCP segment that
has 20 bytes of header, an IP datagram with 20 bytes of header and so on down
the layers. We are sending 41 bytes of information for 1 byte of data. Such a
packet is called a _tinygram_. The proliferation of tinygrams causes addditional
congestion in a network. Nagle created a strategy for reducing this. It applies
to the sender of the tinygram (client) rather than the server. 

Nagles Algorithm:

_a TCP connection can have only one outstanding unACKed small segment: no
additional small segments can be sent until that ACK has been received._

If you have several tinygrams you want to send, you should collect them together
into a single larger segment that is sent when the ACK is received. This segment
can also be sent if either a) you collect enough small segments to fill an MSS
segment, or b) they have collectively exceeded half the destination advertised
window size. The definition of a "small" packet is open for interpretation,
which can be anything from 1 byte, to any segment short than the maximum segment
size. This is a very simple strategy and reduces the number of tinygrams without
introducing extra perceived delay (over the delay that is already there). The
faster ACKs come back, the more tinygrams can be sent. When there is congestion,
ACKs return more slowly and fewer tinygrams are sent. Nagle can reduce the
number of segments significantly when the network is heavily loaded. On the
other hand sometimes buffering up tinygrams is not a good idea. e.g. In a
graphical interface over a network each mouse movement becomes a tinygram.
Buffering the segments would cause the cursor to jump erratically.

Another problem with tinygrams is manifested as silly window syndrome. A is
sending data to B, but B is reading only one byte at a time. B's buffer fills
and B ACKs with a window of 0. B reads a byte and will send a window update
segment, with AWS size=1. A receives this and sends as much data as possible, 1
byte. B ACKs with a window of size=0. B reads a byte and sends an update of size
1 and the pattern repeats. This means there is up to 3 segments per byte send.
The solution here is simple, B should not send an update of 1 but wait until
there is more space. Clarke's algorithm to avoid SWS is in the server:

_Never send an update for a window of 1; only advertise a new window when either
(a) there is enough space for a full segment, or (b) the buffer is half empty_

Nagle and SWS fit together naturally. When window scaling is in effect, "small"
must be at least the size of the window scale as we can't advertise a window
smaller than that. Note that TCP does not have to implement either of these
strategies, it's just a good idea.

Nagle and SWS are good for when there is a small amount of data being
transmitted. There are other strategies that one could employ for sending large
amounts of data. We want to get the destination as fast as possible but we now
have to consider not just the ability of the destination to cope, but also the
capacity of the network itself. 

Congestion happens when more data is being sent than the network can handle:
routers will drop packets if there is not enough onward bandwidth to cope. There
are several strategies in TCP to deal with and help avoid congestion. It can
deal with congestion with its built in reliability. The first issue is how to
spot congestion, given that it might be happening in a part of the network many
hops away. The way this is done is by watching for segment loss. Segments can be
lost through errors in transmission or being dropped at a congested router (or
the destination). Poor transmission is unusual these days, so we can assume that
loss is due to congestion - much more common. Thus, TCP treats missing or
duplicate ACKs as a sign of congestion. Just as the advertised window deals with
congestion in the destination, we have the congestion window for congestion in
the network. So how do we determine the congestion window? It's not a thing the
source or destination can know directly. If we have a lot of data to send we do
not want to wait for each ACK before sending the next  segment. Better is to
send several segments and then wait to see from the ACKs which were safely
received. Time spent waiting, is time we might have been sending data. But
sending too many segments at once is bad for the case when the network is
congested: our segments will be dropped and we will be making things worse for
everyone else in the process. So if we estimate the capacity of the network, we
will be sending many segments at once, but not too many - we need to find the
sweet spot. If we get it right, we will have a continual stream of segments
going out and ACKs coming back. We estimate congestion by watching the number of
ACKs coming back. This estimate controls the congestion window. This is another
constraint on sending additional to the advertised window. We should not send
more than either of these. 

We describe a basic flow control strategy that estimates the congestion window.
There are many modifications that exist including TCP Tahoe, TCP Reno. The
congestion window (cwnd) is initialised to the maximum segment size of the
destination. A variable ssthresh, the threshold is initialised to 64kb (for
example). Everytime a timely ACK is received, the congestion window is increased
by one segment.  Initially send one segment, and wait for the ACK, and each time
we receive an ACK, increase the segments we send at once. This is called _slow
start_. It is slow in comparison with an earlier version that started by
blasting out segments as fast as possible before the performance of the network
was known. The increase continues until we reach the current threshold ssthresh
or something goes wrong. The rate is also limited by the advertised window of
the destination. We can only send the minimum of the current congestion window
and the advertised window. If we reach ssthresh without a problem, we change to
the congestion avoidance phase. We increase the cwnd by one segment for each
round trip time. This is one per burst of segments. This changes the ramp up to
linear rather than exponential. Eventually the networks' limit will be reached
and a congested router somewhere will start dropping segments. The sender will
see this when either it gets some duplicate ACKs or there is timout. This could
happen in either of the phases, particularly if ssthresh as initially set very
large as its often done these days.

When congestion is detected, the threshold ssthresh is set to half the current
transmit size. This is the smaller of the current congestion window and the
advertised window. Also this is rounded up to minimum of two segments. If it was
a timeout, the congestion window cwnd is set back to one segment and go back
into slow start. When ACKs start coming through, we resume increasing the
congestion window again according to whether we were in slow start or congestion
avoidance. The sender will eventually converge to a rate that is neither too
fast, nor too slow. It is a fair algorithm, but does guarantee that something
will go wrong eventually as it keeps increasing. It is however dynamic, so if
conditions in the network change, it will soon adapt to the new rate, be it
faster or slower. If there is no congestion on the network, the rate increases
until it reaches the advertised window: the limiting factor will be the
destination not the network. This strategy is very effective, get the flow up
quickly but don't overshoot and back off quickly if something starts to go
wrong. 

As previously mentioned, when an out of order segment is received the TCP
protocol calls for an immediate ACK: it must not be delayed. Thus the sender
should start seeing duplicate ACKs. Jacobson's Fast Retransmit strategy builds
on the idea that the receipt of several duplicated ACKs is indicative of a lost
segment. If three duplicate ACKs are received, the sender should retransmit the
indicated segment immediately. Jacobsen says, do not go into slow start but do
congestion avoidance instead, if this happens. We don't want slow start as the
duplicate ACKs indicate that later has reached the destination and is buffered
there. Data is still mostly arriving and we don't want to abruptly cut the flow
by doing slow start. Using these strategies we can be effective at getting the
flow going again after a loss. There have been many tweaks to this basic flow
control stategy:

- Larger initial ssthresh
- Larger initial cwnd
- Slow start counting number of segments ACKed not just number of ACKs
- Treating duplicate ACKs like a timeout
- On timeout, set cwnd to half ssthresh not just 1.
- Fast recovery: wait for the ACK of the entire transmit window before
    congestion avoidance.
- Many more.

Other strategies exist and are used. An example of this is called Explicit
Congestion Notification (ECN), which is a flag in the IP header that aims to
indicate congestion before it happens by routers setting flags on the segment
when they think congestion is imminent.
