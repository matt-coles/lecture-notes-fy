# Networking
The next TCP field, is the checksum field. This is a checksum of the header, the
data, and _some fields of the IP layer_. This is bad design as it links the
layers together.

There is an urgent pointer, which is only active if the URG flag is set. The
urgent pointer is a pointer into the data stream that indicates where the
current urgent data block ends. Urgent data includes things like interrupts that
need to be processed before any other data that is buffered. The OS should
notify the application when an URG is received e.g. using an interrupt. The OS
interrupt code would then read through the urgent data block and act
appropriately on what it finds there. A similar flag exists, called the PSH
flag. This is set to indicate the destination OS should pass data to the
application as soon as possible. The destination OS might be buffering data for
some reason before passing it on to the application e.g. collecting together
segments into one large buffer for efficiency reasons. This flag says send the
buffered data to the application, don't wait. Originally it was intended the
client application could set the PSH when it felt the server should not be
hanging about buffering data. These days there is no mechanism in the sockets
API for applications to specify this but the TCP software itself sets PSH when
appropriate. When the client's send buffer is empty. The idea is that there is
no point for the receiver waiting for more data as there is no more to send
right now. After the fixed header there are options.

TCP is connection oriented which means that a connection needs to be set up
before data can be sent between the source and destination. All packets that
flow within this connection are related, through the sequence numbers. For
example a connection to fetch a web page will involve many segments. The
underlying layer, usually IP is not connection oriented and each individual
datagram might take a different route to its destination.  This connection is a
weak kind of session, though no further session mechanism is provided.

Setting up a TCP connection is complicated, as there is a lot of state that must
be set up, e.g. sequence numbers, initial advertised windows etc. Similar
closing a connection is not trivial, we must ensure all segments in flight have
been ACKed. Thus a connection will hang around for a little while after closing
to ensure everything is tidied up. Fortunately all this detail is taken care of
by the TCP layer software in the OS. Thought it does have occasionally
repercussions in the application if the connection needs to outlive the
application for some reason. Three segments are needed to make a connection. The
initiator, the _client_ sends a segment with the SYN flag set and its initial
sequence number (ISN), _n_ is randomly generated. The receiver, the _server_,
replies with another SYN segment containing it's own ISN, m. It also ACKs the
clients ISN with n+1, the sequence number of the next byte it expects from the
client. The client must then ACK the server's ISN with m+1. 

This is called the TCP three way handshake. These segments contain no data: they
are simply overhead in setting up the connection. This is overhead in both time
and packets present in the network. After the handshake we can start sending
data. The client, is said to do an active open, whilst the server does a passive
open. It is possible (but rare) for both hosts to do an active open, where the
SYNs cross each other in flight. Matched TCP port numbers will identify when
this happens. This is defined to produce one new connection, not two.

Closing a connection takes up to four segments. TCP is full duplex, and a
connection in one direction may be closed independently of the other. You can
also close a connection with the RST packet, which just means ends this
connection right now, as the receiving server doesn't know what to do with it.

The TIME_WAIT state is the final state in the FSM for a TCP connection, the
connection must remain non-closed until a time period has passed. To make sure
that nothing got lost. Just because the application has closed its end of the
connection it doesn't mean the connection is finished and the OS can discard all
the connection state. The maximum segment lifetime (MSL) is a value that
represents the longest time a segment can be live in the network before being
discard (probably through TTL expiry). This was originally defined to be 2
minutes but implementations often choose smaller values like 60 seconds. A TCP
connection is required to stay in TIME_WAIT for twice that length. This is in
case the final ACK (of the final FIN) was lost and needs retransmitted. The OS
has to keep the connection hanging around for a little bit to cover this case.
Even if the process that used the connection has exited. And while in this wait
state if a new process tries to make a connection using the same ports it will
be defined. We don't want to deliver late packets to the new process. 

TCP options are many and varied. Options start with a 1 byte _kind_ which
indicates what the option is to do. Kinds 0 and 1 are 1 byte long only, and
others have a length field. A NOP is used to pad to align fields to a multiple
of 4 bytes.  Maximum segment size(MSS) specifies how large a segment we can cope
with: the headers are not included in the count. This might be a segment that is
reconstructed from more than one IP fragment. A TCP implementation must be able
to process an MSS of 536 bytes. The MSS is usually communicated in the option
header in the setup of a TCP connection and is typically set to avoid
fragmentation. As previously mentioned the window scale option allows us to
multiple up the value in the advertised window size header field. This optional
field contains a value from 0 to 14. A value of _n_ scales by 2<sup>n</sup>.
Thus a maximum window of 2<sup>14</sup> x 65535 = 1,073,725,440 bytes (a
gigabyte). That's still only one seconds worth of data in a 10Gb/s Ethernet. A
large window is very important in modern fast networks to get the most out of
the available bandwidth. The TS - or time stamp - field puts the time of day
into the segment header, allowing accurate measurement of the round trip time
(RTT) of a segment and its ACK. Useful for computing retransmission times. A
timestamp echo reply (TS ECR) in an ACK segment is the timestamp being returned
to the sender so it can computer the RTT. Selective acknowledgement (SACK) is an
extension of the ACK mechanism that allows more flexible ways of acknowledging
segments. SACK is negotiated in the connection set-up with a SACK permitted
option. Several options are only allowed in SYN segments e.g. window scale, MSS
and SACK permitted. This is because some things e.g. buffer space, need to be
set up before a connection and varying them mid-connection is difficult or makes
little sense.

We now take a look at how TCP manages to get the best out of a connection. For
example: TCP gets reliability by acknowledging every byte sent. Does this mean
two segments for every data packet: one data packet out, one ACK packet back? It
is possible to implement TCP like this but performance would be slow. So a
typical TCP implementation will be a bit more smart on it's use of ACKs: we have
already mentioned delaying an ACK to let it piggyback on a returning data
segment. That is just the first of many strategies a TCP implementation can
employ whilst still following the TCP protocol. We shall look at a few basic
strategies, starting with more detail on the advertised window.

As data arrives at its destination the OS puts it into a buffer, ready for the
receiving application to read it. The TCP advertised window in a returning
segment indicates how much of this buffer space is left. The space left depends
on how fast the sender is sending the data hand how fast the application is
reading the data. If the data arrives faster than it is read the buffer will
fill up. The advertised window is how TCP tells the source to slow down or speed
up. It is a sliding window mechanism used as a form of flow control. A sliding
window describes the range of bytes the sender can transmit. As the window gets
smaller, the sender should send more slowly. As the window gets buffer, the
sender can send more quickly. The sender recomputes the space available in the
receiver every time it sends an ACK. The left hand edge of the window is defined
by the acknowledgement number in the latest ACK. The right hand edge is then
given by adding on the size of the advertised window. The window size is sent in
every segment. As more ACKs are received the window closes as data is received.
As the application reads data the window opens as the right edge advances.
Rarely the window can shrink, perhaps if the buffer shrinks due to the memory
being needed elsewhere. The sender must always compute the free space, by the
number of bytes it has sent. When teh receiver is ready for more data(after AWS
was 0), it will send a duplicate ACK but with a non-zero window, called a window
update segment. It may or may not contain data. Complications arise if this
window update gets lost: the _Persist Timer_ is used here. So the advertised
window is a simple mechanism for providing flow control. As previously mentioned
instead of immediately ACKing every segment, we can slightly delay it. For
example when logged in to a remote terminal each keystroke is echoed back to
your screen. The server could delay the ACK for receiving the keystroke until it
is ready to echo the key back to you. The end result is no different to the user
except maybe it is faster on an _extremely_ slow network. IT is important to
reduce the traffic on a heavily loaded network. It also reduces the chance of a
lost segment. By delaying, we might be able to ACK more than one segment at a
time. If we receive say three segments in a period we are delaying, we can
simply ACK the last segment, this implicitly ACKs the previous two segments.
This begs the question, how long should one wait to delay the ACK. If too long,
the sender might think the segment was lost, if too short we do not get so many
free piggybacks or multiple ACKed segments. A typical implementation will delay
for up to 200ms. The TCP specification states that you must not delay for more
than 500ms. This is one of the many timers associated with TCP. EAch time you
receive a data segment, the TCP software sets a timer for that segment to expire
after 200ms. If the segment has not already been ACKed, ACK it when the timer
expires. Many operating systems have a single global timer that fires every
200ms rather than a timer per segment received. This is less accurate but much
easier to implement.
